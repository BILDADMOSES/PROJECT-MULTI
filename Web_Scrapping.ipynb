{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scraping Process for Player Match Logs\n",
    "\n",
    "This document outlines the steps involved in scraping match log data for a specific player from the website `fbref.com`.\n",
    "\n",
    "## 1. Objective\n",
    "\n",
    "The goal is to scrape match log data for a player (e.g., Phil Foden) across multiple seasons and compile the data into a single pandas DataFrame.\n",
    "\n",
    "## 2. Data Source\n",
    "\n",
    "The data is sourced from `fbref.com`, which provides detailed match logs for various football players. The match logs include details such as match dates, competition names, venues, results, and player statistics.\n",
    "\n",
    "## 3. Steps Involved\n",
    "\n",
    "### 3.1. Generate Yearly URLs\n",
    "\n",
    "For each season (e.g., \"2021-2022\", \"2020-2021\", \"2019-2020\"), a URL is generated that points to the specific match logs page for the player.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "def generate_yearly_url(year):\n",
    "    base_url = \"https://fbref.com/en/players\"\n",
    "    url = f\"{base_url}/matchlogs/{year}/Phil-Foden-Match-Logs\"\n",
    "    return url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mechanicalsoup\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Enter Player Name\n",
    "player_name = \"Kai-Havertz\"\n",
    "\n",
    "col_names = ['Day',\n",
    "             'Comp',\n",
    "             'Round',\n",
    "             'Venue',\n",
    "             'Result',\n",
    "             'Squad',\n",
    "             'Opponent',\n",
    "             'Start',\n",
    "             'Pos',\n",
    "             'Min',\n",
    "             'Gls',\n",
    "             'Ast',\n",
    "             'PK',\n",
    "             'PKatt',\n",
    "             'Sh',\n",
    "             'SoT',\n",
    "             'CrdY',\n",
    "             'CrdR',\n",
    "             'Touches',\n",
    "             'Tkl',\n",
    "             'Int',\n",
    "             'Blocks',\n",
    "             'xG',\n",
    "             'npxG',\n",
    "             'xAG',\n",
    "             'SCA',\n",
    "             'GCA',\n",
    "             'Cmp',\n",
    "             'Pass_Att',\n",
    "             'Cmp%',\n",
    "             'PrgP',\n",
    "             'Carries',\n",
    "             'PrgC',\n",
    "             'TakeOns_Att',\n",
    "             'Succ',\n",
    "             'Match Report']\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Data for a Given Year\n",
    "For each generated URL, we open the page using mechanicalsoup, a Python library designed for web scraping and automation. The HTML content is parsed to extract the relevant data, such as match dates, competition details, and player performance statistics. The data is then stored in a pandas DataFrame for further processing.\n",
    "\n",
    "Extracting Data: We specifically target HTML elements that contain the required data using CSS class selectors. By filtering out unnecessary data, we focus only on the relevant information.\n",
    "\n",
    "Handling Inconsistencies: To ensure data consistency, we calculate gaps between occurrences of key elements (e.g., \"Match Report\") and use these to accurately identify and structure the data.\n",
    "\n",
    "Storing Data: The extracted data is stored in a DataFrame, which provides a tabular structure for easy analysis and manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def yearly_url_func(year):\n",
    "    base_url = \"https://fbref.com/en/players/fed7cb61/matchlogs\"\n",
    "    \n",
    "    url = f\"{base_url}/{year}/{player_name}-Match-Logs\"\n",
    "    \n",
    "    return url\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling Data Across Multiple Seasons\n",
    "\n",
    "Once we have scraped data for each season, we compile all the data into a single DataFrame. This is done by concatenating individual DataFrames corresponding to each season. The compiled data can then be used for analysis, visualization, or any other processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape_data_for_year(year):\n",
    "    browser = mechanicalsoup.StatefulBrowser()\n",
    "    url = yearly_url_func(year)\n",
    "    \n",
    "    try:\n",
    "        browser.open(url)\n",
    "        # Scraping the data for the given year\n",
    "        \n",
    "        th_elements = browser.page.find_all(\"th\", attrs={\"class\": 'left'})\n",
    "        \n",
    "        filtered_th_elements = [th for th in th_elements if \"iz\" not in th.get(\"class\", [])]\n",
    "\n",
    "    \n",
    "        Date = [value.text for value in filtered_th_elements] # We're only interested in the text not text plus tags\n",
    "    \n",
    "        td_elements = browser.page.find_all(\"td\", attrs={\"class\": lambda x: x and 'left iz' not in x and 'left iz group_start' not in x and 'center iz' not in x})\n",
    "        \n",
    "        filtered_td_elements = [td for td in td_elements]\n",
    "        \n",
    "        columns = [value.text for value in filtered_td_elements]\n",
    "        \n",
    "                \n",
    "        consistent_occurrences = []\n",
    "        target_gap = 36  # We have a total of 36 columns\n",
    "\n",
    "        # Iterate through the list and find occurrences\n",
    "        for i in range(len(columns)):\n",
    "            if columns[i] == 'Match Report':\n",
    "                consistent_occurrences.append(i)\n",
    "\n",
    "        # Create a list to store rows\n",
    "        consistent_rows = []\n",
    "\n",
    "        # Process only the last occurrence in each group\n",
    "        for occurrence in consistent_occurrences:\n",
    "            start_index = occurrence - target_gap + 1\n",
    "            if start_index >= 0:\n",
    "                consistent_rows.append(columns[start_index:occurrence + 1])\n",
    "\n",
    "        # Create a DataFrame with column names\n",
    "        df = pd.DataFrame(consistent_rows, columns=col_names)\n",
    "        df.index = df.index +1\n",
    "        return df  # Return the DataFrame\n",
    "    \n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping data for {year}: {e}\")\n",
    "        return None\n",
    "    \n",
    "    finally:\n",
    "        browser.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage:\n",
    "years = [\"2016-2017\",\"2017-2018\",\"2018-2019\",\"2019-2020\",\"2020-2021\",\"2021-2022\", \"2022-2023\", \"2023-2024\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "for year in years:\n",
    "    df = scrape_data_for_year(year)\n",
    "    if df is not None:  # Check if the DataFrame is not None\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate the DataFrames if the list is not empty\n",
    "if dfs:\n",
    "    final_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    \n",
    "    # DATA PREPROCESSING LOGIC   \n",
    "    final_df['Player'] = player_name\n",
    "    # Removing rows with non-date values in Days Column\n",
    "    days_to_keep = ['Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat']\n",
    "    final_df = final_df[final_df['Day'].isin(days_to_keep)]\n",
    "    \n",
    "    #Filtering for only Premier League\n",
    "    final_df = final_df[final_df['Comp'] == 'Premier League']\n",
    "    \n",
    "    #Will have little variance since they are the same throughout the rows\n",
    "    columns_to_drop = ['Day', 'Comp', 'Round', 'CrdY', 'CrdR', 'Match Report']\n",
    "    final_df = final_df.drop(columns=columns_to_drop)\n",
    "    \n",
    "    #Since every data type was intially object, we need to ensure we have int where we only have integers\n",
    "    numeric_columns = ['Min', 'Gls', 'Ast', 'PK', 'PKatt', 'Sh', 'SoT', 'Touches', 'Tkl', 'Int', 'Blocks', 'xG', 'npxG', 'xAG', 'SCA', 'GCA', 'Cmp', 'Pass_Att', 'Cmp%', 'PrgP', 'Carries', 'PrgC', 'TakeOns_Att', 'Succ']\n",
    "\n",
    "    final_df[numeric_columns] = final_df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    \n",
    "    # Extract team's and opponent's goals from 'Result' column\n",
    "    final_df[['TeamGoals', 'OpponentGoals']] = final_df['Result'].str.extract(r'(\\d+)â€“(\\d+)')\n",
    "    final_df[['TeamGoals', 'OpponentGoals']] = final_df[['TeamGoals', 'OpponentGoals']].astype(int)\n",
    "\n",
    "    # Create a binary column for win\n",
    "    final_df['Win'] = final_df.apply(lambda row: 1 if row['TeamGoals'] > row['OpponentGoals'] else 0, axis=1)\n",
    "\n",
    "    # Create a binary column for draw\n",
    "    final_df['Draw'] = final_df.apply(lambda row: 1 if row['TeamGoals'] == row['OpponentGoals'] else 0, axis=1)\n",
    "\n",
    "    # Create a binary column for loss\n",
    "    final_df['Loss'] = final_df.apply(lambda row: 1 if row['TeamGoals'] < row['OpponentGoals'] else 0, axis=1)\n",
    "\n",
    "    final_df['TotalGoals'] = final_df['TeamGoals'] + final_df['OpponentGoals']\n",
    "\n",
    "    \n",
    "    #Finally drop the Result Column\n",
    "    final_df = final_df.drop(columns = 'Result')\n",
    "    \n",
    "    # Save the final DataFrame\n",
    "    final_df.to_csv(f\"{player_name}.csv\", index = False, encoding='utf-8')\n",
    "    \n",
    "    \n",
    "    \n",
    "else:\n",
    "    print(\"No data available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Venue             object\n",
       "Opponent          object\n",
       "Start             object\n",
       "Pos               object\n",
       "Min                int64\n",
       "Gls                int64\n",
       "Ast                int64\n",
       "PK                 int64\n",
       "PKatt              int64\n",
       "Sh                 int64\n",
       "SoT                int64\n",
       "Touches            int64\n",
       "Tkl                int64\n",
       "Int                int64\n",
       "Blocks             int64\n",
       "xG               float64\n",
       "npxG             float64\n",
       "xAG              float64\n",
       "SCA                int64\n",
       "GCA                int64\n",
       "Cmp                int64\n",
       "Pass_Att           int64\n",
       "Cmp%             float64\n",
       "PrgP               int64\n",
       "Carries            int64\n",
       "PrgC               int64\n",
       "TakeOns_Att        int64\n",
       "Succ               int64\n",
       "Player            object\n",
       "TeamGoals          int32\n",
       "OpponentGoals      int32\n",
       "Win                int64\n",
       "Draw               int64\n",
       "Loss               int64\n",
       "TotalGoals         int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Venue', 'Opponent', 'Start', 'Pos', 'Min', 'Gls', 'Ast', 'PK', 'PKatt',\n",
       "       'Sh', 'SoT', 'Touches', 'Tkl', 'Int', 'Blocks', 'xG', 'npxG', 'xAG',\n",
       "       'SCA', 'GCA', 'Cmp', 'Pass_Att', 'Cmp%', 'PrgP', 'Carries', 'PrgC',\n",
       "       'TakeOns_Att', 'Succ', 'Player', 'TeamGoals', 'OpponentGoals', 'Win',\n",
       "       'Draw', 'Loss', 'TotalGoals'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_player = final_df[['Venue',\n",
    "             'Opponent',\n",
    "             'Start',\n",
    "             'Pos',\n",
    "             'Min',\n",
    "             'Gls',\n",
    "             'Ast',\n",
    "             'PK',\n",
    "             'PKatt',\n",
    "             'Sh',\n",
    "             'SoT',\n",
    "             'Touches',\n",
    "             'Tkl',\n",
    "             'Int',\n",
    "             'Blocks',\n",
    "             'xG',\n",
    "             'npxG',\n",
    "             'xAG',\n",
    "             'SCA',\n",
    "             'GCA',\n",
    "             'Cmp',\n",
    "             'Pass_Att',\n",
    "             'Cmp%',\n",
    "             'PrgP',\n",
    "             'Carries',\n",
    "             'PrgC',\n",
    "             'TakeOns_Att']]\n",
    "\n",
    "y_player = final_df[['Win', 'Draw', 'Loss']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train_player, X_test_player, y_train_player, y_test_player = train_test_split(X_player, y_player, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a player-level model (Random Forest Classifier in this example)\n",
    "player_model = RandomForestClassifier(random_state=42)\n",
    "player_model.fit(X_train_player, y_train_player)\n",
    "\n",
    "# Get predictions for each player in the test set\n",
    "player_predictions = player_model.predict(X_test_player)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
