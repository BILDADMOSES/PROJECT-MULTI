{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scraping Process for Player Match Logs\n",
    "\n",
    "This document outlines the steps involved in scraping match log data for a specific player from the website `fbref.com`.\n",
    "\n",
    "## 1. Objective\n",
    "\n",
    "The goal is to scrape match log data for a player (e.g., Phil Foden) across multiple seasons and compile the data into a single pandas DataFrame.\n",
    "\n",
    "## 2. Data Source\n",
    "\n",
    "The data is sourced from `fbref.com`, which provides detailed match logs for various football players. The match logs include details such as match dates, competition names, venues, results, and player statistics.\n",
    "\n",
    "## 3. Steps Involved\n",
    "\n",
    "### 3.1. Generate Yearly URLs\n",
    "\n",
    "For each season (e.g., \"2021-2022\", \"2020-2021\", \"2019-2020\"), a URL is generated that points to the specific match logs page for the player.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "def generate_yearly_url(year):\n",
    "    base_url = \"https://fbref.com/en/players\"\n",
    "    url = f\"{base_url}/matchlogs/{year}/Phil-Foden-Match-Logs\"\n",
    "    return url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mechanicalsoup\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Enter Player Name\n",
    "player_name = \"Kai-Havertz\"\n",
    "\n",
    "col_names = ['Day',\n",
    "             'Comp',\n",
    "             'Round',\n",
    "             'Venue',\n",
    "             'Result',\n",
    "             'Squad',\n",
    "             'Opponent',\n",
    "             'Start',\n",
    "             'Pos',\n",
    "             'Min',\n",
    "             'Gls',\n",
    "             'Ast',\n",
    "             'PK',\n",
    "             'PKatt',\n",
    "             'Sh',\n",
    "             'SoT',\n",
    "             'CrdY',\n",
    "             'CrdR',\n",
    "             'Touches',\n",
    "             'Tkl',\n",
    "             'Int',\n",
    "             'Blocks',\n",
    "             'xG',\n",
    "             'npxG',\n",
    "             'xAG',\n",
    "             'SCA',\n",
    "             'GCA',\n",
    "             'Cmp',\n",
    "             'Pass_Att',\n",
    "             'Cmp%',\n",
    "             'PrgP',\n",
    "             'Carries',\n",
    "             'PrgC',\n",
    "             'TakeOns_Att',\n",
    "             'Succ',\n",
    "             'Match Report']\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Data for a Given Year\n",
    "For each generated URL, we open the page using mechanicalsoup, a Python library designed for web scraping and automation. The HTML content is parsed to extract the relevant data, such as match dates, competition details, and player performance statistics. The data is then stored in a pandas DataFrame for further processing.\n",
    "\n",
    "Extracting Data: We specifically target HTML elements that contain the required data using CSS class selectors. By filtering out unnecessary data, we focus only on the relevant information.\n",
    "\n",
    "Handling Inconsistencies: To ensure data consistency, we calculate gaps between occurrences of key elements (e.g., \"Match Report\") and use these to accurately identify and structure the data.\n",
    "\n",
    "Storing Data: The extracted data is stored in a DataFrame, which provides a tabular structure for easy analysis and manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def yearly_url_func(year):\n",
    "    base_url = \"https://fbref.com/en/players/fed7cb61/matchlogs\"\n",
    "    \n",
    "    url = f\"{base_url}/{year}/{player_name}-Match-Logs\"\n",
    "    \n",
    "    return url\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling Data Across Multiple Seasons\n",
    "\n",
    "Once we have scraped data for each season, we compile all the data into a single DataFrame. This is done by concatenating individual DataFrames corresponding to each season. The compiled data can then be used for analysis, visualization, or any other processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape_data_for_year(year):\n",
    "    browser = mechanicalsoup.StatefulBrowser()\n",
    "    url = yearly_url_func(year)\n",
    "    \n",
    "    try:\n",
    "        browser.open(url)\n",
    "        # Scraping the data for the given year\n",
    "        \n",
    "        th_elements = browser.page.find_all(\"th\", attrs={\"class\": 'left'})\n",
    "        \n",
    "        filtered_th_elements = [th for th in th_elements if \"iz\" not in th.get(\"class\", [])]\n",
    "\n",
    "    \n",
    "        Date = [value.text for value in filtered_th_elements] # We're only interested in the text not text plus tags\n",
    "    \n",
    "        td_elements = browser.page.find_all(\"td\", attrs={\"class\": lambda x: x and 'left iz' not in x and 'left iz group_start' not in x and 'center iz' not in x})\n",
    "        \n",
    "        filtered_td_elements = [td for td in td_elements]\n",
    "        \n",
    "        columns = [value.text for value in filtered_td_elements]\n",
    "        \n",
    "                \n",
    "        consistent_occurrences = []\n",
    "        target_gap = 36  # We have a total of 36 columns\n",
    "\n",
    "        # Iterate through the list and find occurrences\n",
    "        for i in range(len(columns)):\n",
    "            if columns[i] == 'Match Report':\n",
    "                consistent_occurrences.append(i)\n",
    "\n",
    "        # Create a list to store rows\n",
    "        consistent_rows = []\n",
    "\n",
    "        # Process only the last occurrence in each group\n",
    "        for occurrence in consistent_occurrences:\n",
    "            start_index = occurrence - target_gap + 1\n",
    "            if start_index >= 0:\n",
    "                consistent_rows.append(columns[start_index:occurrence + 1])\n",
    "\n",
    "        # Create a DataFrame with column names\n",
    "        df = pd.DataFrame(consistent_rows, columns=col_names)\n",
    "        df.index = df.index +1\n",
    "        return df  # Return the DataFrame\n",
    "    \n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping data for {year}: {e}\")\n",
    "        return None\n",
    "    \n",
    "    finally:\n",
    "        browser.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage:\n",
    "years = [\"2016-2017\",\"2017-2018\",\"2018-2019\",\"2019-2020\",\"2020-2021\",\"2021-2022\", \"2022-2023\", \"2023-2024\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output and Analysis\n",
    "\n",
    "After compiling the data, it is stored in a final DataFrame. This DataFrame can be further analyzed to gain insights into the player's performance across different seasons. The data can also be exported to other formats such as CSV for sharing or further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "for year in years:\n",
    "    df = scrape_data_for_year(year)\n",
    "    if df is not None:  # Check if the DataFrame is not None\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate the DataFrames if the list is not empty\n",
    "if dfs:\n",
    "    final_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    \n",
    "    # DATA PREPROCESSING LOGIC   \n",
    "    final_df['Player'] = player_name\n",
    "    # Removing rows with non-date values in Days Column\n",
    "    days_to_keep = ['Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat']\n",
    "    final_df = final_df[final_df['Day'].isin(days_to_keep)]\n",
    "    \n",
    "    #Filtering for only Premier League\n",
    "    final_df = final_df[final_df['Comp'] == 'Premier League']\n",
    "    \n",
    "    #Will have little variance since they are the same throughout the rows\n",
    "    columns_to_drop = ['Day', 'Comp', 'Round', 'CrdY', 'CrdR', 'Match Report']\n",
    "    final_df = final_df.drop(columns=columns_to_drop)\n",
    "    \n",
    "    #Since every data type was intially object, we need to ensure we have int where we only have integers\n",
    "    numeric_columns = ['Min', 'Gls', 'Ast', 'PK', 'PKatt', 'Sh', 'SoT', 'Touches', 'Tkl', 'Int', 'Blocks', 'xG', 'npxG', 'xAG', 'SCA', 'GCA', 'Cmp', 'Pass_Att', 'Cmp%', 'PrgP', 'Carries', 'PrgC', 'TakeOns_Att', 'Succ']\n",
    "\n",
    "    final_df[numeric_columns] = final_df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    \n",
    "    # Extract team's and opponent's goals from 'Result' column\n",
    "    final_df[['TeamGoals', 'OpponentGoals']] = final_df['Result'].str.extract(r'(\\d+)â€“(\\d+)')\n",
    "    final_df[['TeamGoals', 'OpponentGoals']] = final_df[['TeamGoals', 'OpponentGoals']].astype(int)\n",
    "\n",
    "    # Create a binary column for win\n",
    "    final_df['Win'] = final_df.apply(lambda row: 1 if row['TeamGoals'] > row['OpponentGoals'] else 0, axis=1)\n",
    "\n",
    "    # Create a binary column for draw\n",
    "    final_df['Draw'] = final_df.apply(lambda row: 1 if row['TeamGoals'] == row['OpponentGoals'] else 0, axis=1)\n",
    "\n",
    "    # Create a binary column for loss\n",
    "    final_df['Loss'] = final_df.apply(lambda row: 1 if row['TeamGoals'] < row['OpponentGoals'] else 0, axis=1)\n",
    "\n",
    "    final_df['TotalGoals'] = final_df['TeamGoals'] + final_df['OpponentGoals']\n",
    "\n",
    "    \n",
    "    #Finally drop the Result Column\n",
    "    final_df = final_df.drop(columns = 'Result')\n",
    "    \n",
    "    # Save the final DataFrame\n",
    "    final_df.to_csv(f\"{player_name}.csv\", index = False, encoding='utf-8')\n",
    "    \n",
    "    \n",
    "    \n",
    "else:\n",
    "    print(\"No data available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Venue    Squad        Opponent Start    Pos  Min  Gls  Ast  PK  PKatt  \\\n",
      "179  Away  Chelsea        Brighton     Y     AM   79    0    0   0      0   \n",
      "180  Home  Chelsea       Liverpool     Y     FW   45    0    0   0      0   \n",
      "182  Away  Chelsea       West Brom     Y  AM,CM   90    0    1   0      0   \n",
      "184  Home  Chelsea  Crystal Palace     Y     AM   90    0    0   0      0   \n",
      "188  Home  Chelsea     Southampton     Y  AM,LM   90    1    0   0      0   \n",
      "..    ...      ...             ...   ...    ...  ...  ...  ...  ..    ...   \n",
      "421  Home  Arsenal         Chelsea     Y     FW   71    2    0   0      0   \n",
      "422  Away  Arsenal       Tottenham     Y     FW   90    1    1   0      0   \n",
      "423  Home  Arsenal     Bournemouth     Y     FW   90    0    0   0      0   \n",
      "424  Away  Arsenal  Manchester Utd     Y     FW   90    0    1   0      0   \n",
      "425  Home  Arsenal         Everton     Y     FW   90    1    0   0      0   \n",
      "\n",
      "     ...  PrgC  TakeOns_Att  Succ       Player  TeamGoals  OpponentGoals  Win  \\\n",
      "179  ...     1            2     1  Kai-Havertz          3              1    1   \n",
      "180  ...     0            0     0  Kai-Havertz          0              2    0   \n",
      "182  ...     0            1     0  Kai-Havertz          3              3    0   \n",
      "184  ...     4            2     0  Kai-Havertz          4              0    1   \n",
      "188  ...     3            2     1  Kai-Havertz          3              3    0   \n",
      "..   ...   ...          ...   ...          ...        ...            ...  ...   \n",
      "421  ...     2            0     0  Kai-Havertz          5              0    1   \n",
      "422  ...     1            2     1  Kai-Havertz          3              2    1   \n",
      "423  ...     3            2     1  Kai-Havertz          3              0    1   \n",
      "424  ...     1            1     0  Kai-Havertz          1              0    1   \n",
      "425  ...     3            0     0  Kai-Havertz          2              1    1   \n",
      "\n",
      "     Draw  Loss  TotalGoals  \n",
      "179     0     0           4  \n",
      "180     0     1           2  \n",
      "182     1     0           6  \n",
      "184     0     0           4  \n",
      "188     1     0           6  \n",
      "..    ...   ...         ...  \n",
      "421     0     0           5  \n",
      "422     0     0           5  \n",
      "423     0     0           3  \n",
      "424     0     0           1  \n",
      "425     0     0           3  \n",
      "\n",
      "[128 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Venue', 'Squad', 'Opponent', 'Start', 'Pos', 'Min', 'Gls', 'Ast', 'PK',\n",
       "       'PKatt', 'Sh', 'SoT', 'Touches', 'Tkl', 'Int', 'Blocks', 'xG', 'npxG',\n",
       "       'xAG', 'SCA', 'GCA', 'Cmp', 'Pass_Att', 'Cmp%', 'PrgP', 'Carries',\n",
       "       'PrgC', 'TakeOns_Att', 'Succ', 'Player', 'TeamGoals', 'OpponentGoals',\n",
       "       'Win', 'Draw', 'Loss', 'TotalGoals'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_player = final_df[['Venue',\n",
    "             'Opponent',\n",
    "             'Start',\n",
    "             'Pos',\n",
    "             'Min',\n",
    "             'Gls',\n",
    "             'Ast',\n",
    "             'PK',\n",
    "             'PKatt',\n",
    "             'Sh',\n",
    "             'SoT',\n",
    "             'Touches',\n",
    "             'Tkl',\n",
    "             'Int',\n",
    "             'Blocks',\n",
    "             'xG',\n",
    "             'npxG',\n",
    "             'xAG',\n",
    "             'SCA',\n",
    "             'GCA',\n",
    "             'Cmp',\n",
    "             'Pass_Att',\n",
    "             'Cmp%',\n",
    "             'PrgP',\n",
    "             'Carries',\n",
    "             'PrgC',\n",
    "             'TakeOns_Att']]\n",
    "\n",
    "y_player = final_df[['Win', 'Draw', 'Loss']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
